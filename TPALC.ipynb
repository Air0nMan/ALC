{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c74eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión (SVD):\n",
      "[[334 166]\n",
      " [150 350]]\n",
      "Accuracy (SVD): 0.684\n",
      "Matriz de confusión (gs):\n",
      "[[334 166]\n",
      " [150 350]]\n",
      "Accuracy (gs): 0.684\n",
      "Matriz de confusión (cholesky):\n",
      "[[334 166]\n",
      " [150 350]]\n",
      "Accuracy (cholesky): 0.684\n",
      "Matriz de confusión (householder):\n",
      "[[334 166]\n",
      " [150 350]]\n",
      "Accuracy (householder): 0.684\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ALC import *\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "\n",
    "#    [1,0] -> 0   (clase 0)\n",
    "#    [0,1] -> 1   (clase 1)\n",
    "def obtener_clases_reales(Yv):\n",
    "    n = Yv.shape[1]\n",
    "    y_true = np.zeros(n, dtype=int)\n",
    "\n",
    "    for i in range(n):\n",
    "        if Yv[0, i] == 1:\n",
    "            y_true[i] = 0\n",
    "        else:\n",
    "            y_true[i] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "\n",
    "\n",
    "#Predicción de clases con un W dado\n",
    "#    Para cada columna de Y_pred = W . Xv:\n",
    "#    si y0 >= y1 -> clase 0\n",
    "#    si y0 <  y1 -> clase 1\n",
    "def predecir_todas(W, Xv):\n",
    "    Y_pred = W @ Xv          \n",
    "    n = Y_pred.shape[1]\n",
    "    y_pred = np.zeros(n, dtype=int)\n",
    "\n",
    "    for i in range(n):\n",
    "        y0 = Y_pred[0, i]\n",
    "        y1 = Y_pred[1, i]\n",
    "\n",
    "        if y0 >= y1:\n",
    "            y_pred[i] = 0\n",
    "        else:\n",
    "            y_pred[i] = 1\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Matriz de confusión 2x2 \n",
    "#    Filas = clase real, Columnas = clase predicha\n",
    "#       [ [ reales 0 predichos 0, reales 0 predichos 1 ],\n",
    "#         [ reales 1 predichos 0, reales 1 predichos 1 ] ]\n",
    "\n",
    "def matriz_confusion(y_true, y_pred):\n",
    "    matriz = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        matriz[int(t), int(p)] += 1\n",
    "\n",
    "    return matriz\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy: cantidad de aciertos / total\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    aciertos = 0\n",
    "    total = len(y_true)\n",
    "\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        if t == p:\n",
    "            aciertos += 1\n",
    "\n",
    "    return aciertos / total\n",
    "\n",
    "\n",
    "X_t,Y_t,Xv,Yv= cargarDataset(\"\")\n",
    "\n",
    "ranX = rango(X_t)\n",
    "n,p = X_t.shape\n",
    "if ranX == p and n>p:\n",
    "    L,Lt=cholesky(traspuesta(X_t),X_t)\n",
    "elif ranX == n:\n",
    "    if n < p:\n",
    "        L,Lt=cholesky(X_t,traspuesta(X_t))\n",
    "    elif n == p:\n",
    "        L,Lt=cholesky(X_t)\n",
    "\n",
    "Qhh,Rhh= QR_con_HH(traspuesta(X_t))\n",
    "Qgs,Rgs= QR_con_GS(traspuesta(X_t))\n",
    "U,S,V= svd_reducida(X_t)\n",
    "\n",
    "W_svd=pinvSVD(U,S,V,Y_t)\n",
    "W_cholesky= pinvEcuacionesNormales(X_t,L,Y_t)\n",
    "W_gs= pinvGramSchmidt(Qgs,Rgs,Y_t)\n",
    "W_hh= pinvHouseHolder(Qhh,Rhh,Y_t)\n",
    "\n",
    "# Clases reales a partir de Yv (one-hot)\n",
    "y_real = obtener_clases_reales(Yv)\n",
    "\n",
    "# Clases predichas usando W_svd\n",
    "y_pred_svd = predecir_todas(W_svd, Xv)\n",
    "\n",
    "# Matriz de confusión y accuracy para SVD\n",
    "matriz_svd = matriz_confusion(y_real, y_pred_svd)\n",
    "acc_svd = accuracy(y_real, y_pred_svd)\n",
    "\n",
    "print(\"Matriz de confusión (SVD):\")\n",
    "print(matriz_svd)\n",
    "print(\"Accuracy (SVD):\", acc_svd)\n",
    "\n",
    "y_pred_gs = predecir_todas(W_gs, Xv)\n",
    "\n",
    "# Matriz de confusión y accuracy para SVD\n",
    "matriz_gs = matriz_confusion(y_real, y_pred_gs)\n",
    "acc_gs = accuracy(y_real, y_pred_gs)\n",
    "\n",
    "print(\"Matriz de confusión (gs):\")\n",
    "print(matriz_gs)\n",
    "print(\"Accuracy (gs):\", acc_gs)\n",
    "\n",
    "y_pred_cholesky = predecir_todas(W_cholesky, Xv)\n",
    "\n",
    "# Matriz de confusión y accuracy para cholesky\n",
    "matriz_cholesky = matriz_confusion(y_real, y_pred_cholesky)\n",
    "acc_cholesky = accuracy(y_real, y_pred_cholesky)\n",
    "\n",
    "print(\"Matriz de confusión (cholesky):\")\n",
    "print(matriz_cholesky)\n",
    "print(\"Accuracy (cholesky):\", acc_cholesky)\n",
    "\n",
    "y_pred_hh = predecir_todas(W_hh, Xv)\n",
    "\n",
    "# Matriz de confusión y accuracy para cholesky\n",
    "matriz_hh = matriz_confusion(y_real, y_pred_hh)\n",
    "acc_hh = accuracy(y_real, y_pred_hh)\n",
    "\n",
    "print(\"Matriz de confusión (householder):\")\n",
    "print(matriz_hh)\n",
    "print(\"Accuracy (householder):\", acc_hh)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e96c3b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Método  Tiempo (minutos)  Accuracy\n",
      "0  Gram-Schmidt                11     0.684\n",
      "1   Householder                28     0.684\n",
      "2           SVD                55     0.684\n",
      "3      Cholesky                56     0.684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Datos\n",
    "metodos = [\"Gram-Schmidt\", \"Householder\", \"SVD\", \"Cholesky\"]\n",
    "tiempos = [11, 28, 55, 56]  # en minutos\n",
    "accuracy = [0.684, 0.684, 0.684, 0.684]  # mismo valor para todos\n",
    "\n",
    "# Crear DataFrame\n",
    "tabla = pd.DataFrame({\n",
    "    \"Método\": metodos,\n",
    "    \"Tiempo (minutos)\": tiempos,\n",
    "    \"Accuracy\": accuracy\n",
    "})\n",
    "\n",
    "print(tabla)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5477a8",
   "metadata": {},
   "source": [
    "En este trabajo aplicamos distintos metodos para obtener la matriz de pesos W, lo que nos permite aproximar la relacion entre los embeddings de entrada X y las etiquetas Y calculando la pseudoinversa. \n",
    "Utilizamos 4 metodos: \n",
    "\n",
    "\"Ecuaciones normales con Cholesky\"\n",
    "\"Descomposicion QR usando Gram-Schmidt\n",
    "\"Descomposicion QR usando House-Holder\n",
    "\"Descomposicion en Valores singulares.\n",
    "\n",
    "Primero implementamos las funciones auxiliares manualmente  (producto externo, traspuesta, norma, multiplicación), respetando las restricciones del laboratorio.  Las funciones del labo andaban bien para matrices pequeñas, pero cuando intentamos aplicarlas sobre los embeddings reales de tamaño 1536×2000 y 2000×2, se volvieron extremadamente lentas e incluso nuestro código llegó a sobrecalentar la computadora. Esto se debe a que las versiones originales realizaban bucles anidados, lo cual funcionaba para los casos de test con matrices pequeñas, pero el costo computacional se hacía inviable para matrices tan grandes. Por eso, mantuvimos la estructura de nuestros algoritmos, pero cambiamos algunas partes internas usando funciones de NumPy (como @ para multiplicación, slicing y np.sum), logrando una gran mejora en tiempos (el código terminó de correr sin explotar la memoria, y en menos de una hora).\n",
    "\n",
    "Aplicamos los cuatro metodos para obtener la matriz W. La guardamos para cada caso y luego la usamos para validar sobre Xv e Yv. Todos los métodos predijeron exactamente lo mismo, tuvieron la misma matriz de confusion. Esto dio una accuracy del 68.4% en los cuatro casos. Esto nos indica que, al menos para este problema, los métodos convergen a soluciones equivalentes y que el sistema no está mal condicionado.\n",
    "\n",
    "La gran diferencia estuvo en los tiempos: Gram-Schmidt fue el más rápido, tardando 11 minutos. Householder tardó 28 minutos, SVD tardó 55 minutos, y Cholesky fue la mas lenta, tardando 56 minutos. \n",
    "\n",
    "En conclusión, aunque todos los métodos dieron el mismo resultado de clasificación, no todos son igual de prácticos si tenemos en cuenta los tiempos de ejecución. Además, comprobamos que fue necesario optimizar las funciones del laboratorio para que el cálculo sea viable en matrices reales de gran tamaño.\n",
    ".\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
