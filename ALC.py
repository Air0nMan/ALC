# -*- coding: utf-8 -*-
"""py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XM63xWkLvCpbsO-PjwO0bx87qVXXaGz-
"""

import numpy as np
import math

def esCuadrada(matrizInput):
    if(len(matrizInput[0]) == len(matrizInput)):
        return True
    else:
        return False


def triangSup(A):
    A = A.copy().astype(float)
    n, m = A.shape
    k = min(n, m)   # por si la matriz no es cuadrada

    for i in range(k):

        # 1. Pivoteo parcial: buscar fila con el mayor valor absoluto en la columna i
        if A[i, i] == 0:
            for j in range(i + 1, n):
                if A[j, i] != 0:
                    A[[i, j]] = A[[j, i]]  # swap de filas
                    break

        # Si sigue siendo 0, no se puede eliminar en esta columna
        if A[i, i] == 0:
            continue

        # 2. Eliminación hacia abajo
        for z in range(i + 1, n):
            factor = A[z, i] / A[i, i]
            A[z] = A[z] - factor * A[i]

    return A


def rango(A):
    B = triangSup(A)
    n,m= B.shape
    cont = 0
    for i in range(n):
        vector_nulo = 0
        for j in range(m):
            if B[i][j] != 0:
                continue
            else:
                vector_nulo+=1
        if vector_nulo < m:
            cont+=1   
    return cont




def diagonal(A):
    res = np.zeros(A.shape)
    for i in range (A.shape[0]):
        res[i,i] = A[i,i]
    return res

def vectorDiagonal(A):
    n=len(A)
    res = np.zeros(n,n)
    for i in range(n):
        res[i,i]=A[i]


def intercambiarFilas(A,i,j):
    A=np.array(A)
    A[[i,j]] = A[[j,i]]
    return A


def sumarFilaMultiplo(A,i,j,s):
    A= np.array(A)
    A[i]+= s*A[j]
    return A


def traza(A):
    res = 0
    for i in range (len(A)):
        res+= A[i][i]
    return res




def calcularAx (A, x):
    res = []
    n = len(A)
    m = len(x)

    for i in range(n):
        suma = 0
        for j in range(m):
            suma += A[i][j]*x[j]
        res.append(suma)
    return np.array(res)

def sustitucionInferior(L,b):
    n = L.shape[0]
    x = np.zeros(n)

    for i in range(n):
        suma = 0
        for j in range(i):
            suma += L[i][j] * x[j]
        x[i] = (b[i] - suma) / L[i][i]
    return x

def sustitucionSuperior(U,b):
    n = U.shape[0]
    x = np.zeros(n)

    for i in range(n-1,-1,-1):
        suma = 0
        for j in range(i+1,n):
            suma += U[i][j] * x[j]
        x[i] = (b[i] - suma) / U[i][i]
    return x


def esDiagonalmenteDominante(A):
    for i in range (len(A)):
        suma = 0
        diagonal = 0
        for j in range (len(A[0])):
            if i == j:
                diagonal = abs(A[i][j])
            else:
                suma+= abs(A[i][j])
        if diagonal < suma:
            return False
    return True


def matrizVandermonde(v):
    res = []
    for i in range(len(v)):
        res.append([])
        for j in range(len(v)):
            res[i].append(v[i]**j)
    return np.array(traspuesta(res))



def producto_externo(x,y):

    A = np.zeros((len(x),len(y)))

    for i in range(len(x)):
        for j in range(len(y)):
            A[i][j] = x[i] * y[j]
    return A

def multiplicar_matrices(A, B):
    """m, n = A.shape
    n1, p = B.shape
    if n != n1:
      return None
    C = np.zeros((m, p))

    for i in range(m):
        for j in range(p):
            C[i,j] = multiplicar_vectores(A[i, :], B[:, j]) """
    C = A@B
    return C

def traspuesta(A):
    n,m = A.shape
    res = np.zeros((m,n))
    for i in range(m):
        for j in range(n):
            res[i][j] = A[j][i]
    return res

def esSimetrica(A,atol=0):
  matriz = np.array(A)
  if matriz.ndim !=2:
   return False
  filas, columnas = matriz.shape
  if filas!=columnas:
   return False
  for i in range(filas):
   for j in range(filas):
    if error_relativo(matriz[i][j], matriz[j][i])>atol:
     return False
  return True

#Labo 1
def error(x,y):
  x= np.float64(x)
  y= np.float64(y)
  return np.abs(x-y)


def error_relativo(x,y):
  x=np.float64(x)
  y=np.float64(y)

  if x==0:
    return np.inf
  else:
      return np.abs(x-y)/np.abs(x)


def matricesiguales (A,B,tol=0):
  if A.shape!= B.shape:
    return False
  for i in range (A.shape[0]):
      for j in range (A.shape[1]):
        if error_relativo(A[i][j],B[i][j]) > tol:
          return False
  return True

#labo2

def rota(theta):
  cos_t=np.cos(theta)
  sen_t=np.sin(theta)
  return np.array([[cos_t, -sen_t],[sen_t,  cos_t]])

def escala(s):
  s= np.array(s)
  n=len(s)
  matriz= np.zeros((n,n))
  for i in range (n):
    matriz[i][i]= s[i]
  return matriz

def rotayescala(theta,s):
    res = rota(theta)
    res[0] = res[0]*s[0]
    return np.array(res)

#labo3

def norma(x,p):
    if(p == "inf"): #se rompe en lista vacia
        max = abs(x[0])
        for i in x:
           if(max < abs(i)):
               max = abs(i)
        return max

    sum = 0
    for i in x:
        sum += abs(i)**p
    sum = sum ** (1/p)
    return sum

def normaliza(X, p ):
    res = [None]*len(X)
    for i in range(0,len(X)):
        res[i] = [None]*len(X[i])
        for j in range (len(X[i])):
            res[i][j] = X[i][j]/norma(X[i],p)
    return res

def normaExacta(a,p=[1,"inf"]):
    if p == 2:
        return None

    cantFilas = len(a)
    CantColumnas = len(a[0])

    resinf = 0
    for i in range(0,cantFilas):
        sum = 0
        for j in range(0, CantColumnas):
            sum += abs(a[i][j])
        if sum > resinf:
            resinf = sum

    res1 = 0
    for j in range(0,CantColumnas):
        sum = 0
        for i in range(0, cantFilas):
            sum += abs(a[i][j])
        if sum > res1:
            res1 = sum
    if p == 1:
      return res1
    elif p == "inf":
      return resinf
    return res1,resinf


def _generar_vector_normalizado_p(m, p):

    if p == 2:
        x = np.random.normal(size = m)
    else:
        x = np.random.uniform(-1, 1, m)
    norm_x = norma(x, p)
    if norm_x == 0:
        return np.zeros(m)
    return x / norm_x

def normaMatMC(A, q, p, Np):
    res = 0
    vector_max = None

    A_mat = np.array(A)
    n, m = np.shape(A_mat)

    for i in range(Np):
        x_norm = _generar_vector_normalizado_p(m, p)
        Ax = calcularAx(A_mat, x_norm)
        normaX = norma(Ax, q)

        if normaX > res:
            res = normaX
            vector_max = x_norm

    return res, vector_max

def condExacta(A,p):
    inversa = np.linalg.inv(A)
    res = 0
    if p == 1:
        res = normaExacta(A,p)[0]*normaExacta(inversa)[0]
    elif p == "inf":
        res = normaExacta(A,p)[1]*normaExacta(inversa)[1]
    else:
        res = normaMatMC(A,p,p,10000)[0]* normaMatMC(inversa,p,p,10000)[0]

    return res

def condMC( A, p ):
    inversa = np.linalg.inv(A)
    res = 0
    res = normaMatMC(A,p,p,10000)[0]* normaMatMC(inversa,p,p,10000)[0]
    return res

#labo4
def calculaLU(M):
    if M is None or M.ndim != 2 or M.shape[0] != M.shape[1]:
        return None, None, 0
    M = M.copy().astype(float)
    N = M.shape[0]

    U = M.copy()
    L = np.eye(N)

    contador = 1
    for i in range(N):
        pivot = U[i,i]
        if pivot == 0:
            return None,None,0
        for j in range(i + 1, N):
            coeficiente = U[j, i] / pivot
            U[j, :] -= coeficiente * U[i, :]
            L[j, i] = coeficiente
            contador+=4

    return L,U, contador

def res_tri(L,b, inferior = True):
    n = len(L)
    x = [0.0] * n
    if inferior:
        for i in range( n ):
            suma = 0.0
            for j in range( i ):
                suma += L[i][j] * x[j]
            x[i] = ( b[i] - suma ) / L[i][i]
    else:
        for i in range(n - 1, -1, -1):
            suma = 0.0
            for j in range(i+1, n):
                suma += L[i][j] * x[j]
            x[i] = (b[i] - suma) / L[i][i]
    return x

def inversa(M):
    n = M.shape[0]
    L, U, T = calculaLU(M)
    inversa = np.array([])
    if L is None:
        inversa = None
    else:
        inversa = np.zeros((n, n))
        I = np.eye(n)
        for i in range(n):
            e = I[:, i]
            y = res_tri(L, e, True)
            x = res_tri(U, y, False)
            inversa[:, i] = x

    return inversa

def calculaLDV (A):
  L,U,_ = calculaLU(A)
  if (L is None or U is None):
   return None,None,None
  V,D,_ = calculaLU(traspuesta(U))
  if (D is None or V is None):
     return None,None,None
  return L,D,traspuesta(V)

def cholesky(A):
    L,U,_ = calculaLU(A)
    D = diagonal(U)
    for i in range(L.shape[0]):
        L[:,i] = L[:,i] * np.sqrt(D[i,i])
    return L,traspuesta(L)
    

def esSDP(A,atol=1e-8):
  if A is None:
    return None
  if not esSimetrica(A,atol):
    return False
  L,D,V = calculaLDV(A)
  if D is None:
    return None
  n=A.shape[0]
  for i in range(n):
    if D[i][i] <= atol :
      return False

  return True

def multiplicar_vectores(a,b):
  if len(a)!=len(b):
    return None
  res = 0
  for i in range (len(a)):
    res+=a[i]*b[i]
  return res

def QR_con_GS(A, tol=1e-12,retorna_nops=False):
    m, n = A.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))

    r = 0  # contador de columnas independientes

    for j in range(n):
        # Copiamos la j-ésima columna de A
        v = A[:, j].copy()

        # Proyección sobre las columnas anteriores de Q válidas
        for k in range(r):
            R[k, j] = multiplicar_vectores(Q[:, k], v)
            v -= R[k, j] * Q[:, k]

        # Norma de la componente ortogonal
        R[r, j] = norma(v, 2)

        # Verificar si la norma es suficientemente grande
        if R[r, j] > tol:
            # Guardamos q_r y avanzamos el contador
            Q[:, r] = v / R[r, j]
            r += 1
        # Si no, el vector se descarta (columna dependiente)

    # Construimos matrices finales truncadas
    Q_hat = Q[:, :r]
    R_hat = R[:r, :]

    return Q_hat, R_hat

def QR_con_HH(A, tol=1e-12):
    A = np.array(A, dtype=float)
    m, n = A.shape
    if m < n:
        return None

    R = A.copy()
    Q = np.eye(m)
    print(n)
    for k in range(n):
        print(k)
        x = R[k:, k]
        alfa = -np.sign(x[0]) * norma(x,2)
        e1 = np.zeros_like(x)
        e1[0] = 1
        u = x - alfa * e1

        if norma(u,2) > tol:
            u = u / norma(u,2)

            Hk = np.eye(m-k)-2*producto_externo(u, u)
            Hk_sub = np.zeros((m,m))
            for i in range(k):
                Hk_sub[i,i] = 1
            Hk_sub[k:,k:] = Hk
            

            R = multiplicar_matrices(Hk_sub, R)
            Q = multiplicar_matrices(Q,Hk_sub.T)

    return Q, R


def calculaQR(A,metodo='RH',tol=1e-12):
  if metodo == "RH":
    return QR_con_HH(A,tol)
  elif metodo == "GM":
    return QR_con_GS(A,tol)
  return None

def metpot2k(A, tol=1e-12, K=1000):
    x = len(A[0])
    v = np.random.randn(x)
    v = v / norma(v, 2)

    wa = calcularAx(A, v)
    aval_viejo = 0
    aval_nuevo = multiplicar_vectores(v, wa)
    k = 0

    while k < K and abs(aval_nuevo - aval_viejo) > tol:
        v = wa / norma(wa, 2)
        wa = calcularAx(A, v)
        aval_viejo = aval_nuevo
        aval_nuevo = multiplicar_vectores(v, wa)
        k += 1

    return v, aval_nuevo, k

def diagRH(A,tol=1e-15,K=100):
  n,_ = A.shape
  v,l,_ = metpot2k(A,tol,K)
  H = np.eye(n) - 2* multiplicar_matrices(traspuesta(np.array([np.eye(n)[0]-v])),np.array([np.eye(n)[0]-v])) / (norma(np.eye(n)[0]-v,2))**2
  if (n==2):
    S = H.copy()
    D = multiplicar_matrices(H,multiplicar_matrices(A,traspuesta(H)))
  else:
    B = multiplicar_matrices(H,multiplicar_matrices(A,traspuesta(H)))
    A1 = np.zeros((n-1,n-1))
    for i in range(n-1):
      for j in range(n-1):
        A1[i,j] = B[i+1,j+1]
    S1,D1 = diagRH(A1,tol,K)

    D = np.zeros((n,n))
    D[0,0] = l
    for i in range (1,n):
      D[i,i] = D1[i-1,i-1]
    S=np.eye(n)
    for i in range(1,n):
      for j in range(1,n):
        S[i,j] = S1[i-1,j-1]
    S = multiplicar_matrices(H,S)
  return S,D

#labo7

def transiciones_al_azar_continuas(n):
    M = np.random.rand(n, n)
    suma_columnas = M.sum(axis=0)
    M = M / suma_columnas
    return M

def transiciones_al_azar_uniformes(n, thres):
    M = np.random.rand(n, n)
    M[M < thres] = 1.0
    M[M >= thres] = 0.0

    for j in range(n):
        if M[:, j].sum() == 0:
            M[0, j] = 1

    M = M / M.sum(axis=0)

    return M

def nucleo(A, tol=1e-15):
    A_t = traspuesta(A)
    M = multiplicar_matrices(A_t, A)

    S, D = diagRH(M, tol=tol)

    n_diag = D.shape[0]
    autovalores = np.zeros(n_diag)
    for i in range(n_diag):
        autovalores[i] = D[i, i]
    autovalores = np.abs(autovalores) < tol
    autovectores_nucleo = S[:, autovalores]

    if autovectores_nucleo.shape[1] == 0:
        return np.zeros((0, 0))
    else:
        return autovectores_nucleo

def crea_rala(listado, m_filas, n_columnas, tol=1e-15):

    if len(listado) == 0:
        return {}, (m_filas, n_columnas)

    filas    = listado[0]
    columnas = listado[1]
    valores  = listado[2]

    dic = {}

    cantidad = len(filas)

    for k in range(cantidad):
        i   = filas[k]
        j   = columnas[k]
        aij = valores[k]

        if abs(aij) > tol:
            dic[(i, j)] = aij

    return [dic, (m_filas, n_columnas)]

def multiplica_rala_vector(A, v):
    dic = A[0]
    m_filas, n_columnas = A[1]
    res = np.zeros(m_filas)
    for (i, j), Aij in dic.items():
       res[i] += Aij * v[j]
    return res

def svd_reducida(A, tol=1e-15):
    m, n = A.shape
    AT = traspuesta(A)
    AtA = multiplicar_matrices(AT, A)
    S, D = diagRH(AtA, tol=tol, K=10000)

    n_diag = D.shape[0]
    autovalores = np.zeros(n_diag)

    for i in range(n_diag):
        autovalores[i] = D[i, i]
    perm = np.argsort(-autovalores)
    autovalores = autovalores[perm]
    V = S[:, perm]

    autovalores[autovalores < 0] = 0.0
    valores_propios = np.sqrt(autovalores)

    k = min(m, n)
    valores_k = valores_propios[:k]
    V_k = V[:, :k]

    no_nulos = valores_k > tol
    hS = valores_k[no_nulos]
    r = len(hS)

    if r == 0:
        hU = np.zeros((m, 0))
        hV = np.zeros((n, 0))
        return hU, hS, hV

    hV = V_k[:, no_nulos]
    hU = np.zeros((m, r))
    for j in range(r):
        vj = hV[:, j]
        Avj = calcularAx(A, vj)
        hU[:, j] = Avj / hS[j]

    return hU, hS, hV


#Funciones TP ALC

def cargarDataset(carpeta):

    X_train_cats = np.load(carpeta + "/dataset/cats_and_dogs/train/cats/efficientnet_b3_embeddings.npy")
    X_train_dogs = np.load(carpeta + "/dataset/cats_and_dogs/train/dogs/efficientnet_b3_embeddings.npy")

    Xt = np.concatenate((X_train_cats, X_train_dogs), axis=1)

    n_train_cats = X_train_cats.shape[1]
    n_train_dogs = X_train_dogs.shape[1]
    n_train_total = n_train_cats + n_train_dogs

    Yt = np.zeros((2, n_train_total))
    Yt[0, :n_train_cats] = 1 
    Yt[1, n_train_cats:] = 1  

    X_val_cats = np.load(carpeta + "/dataset/cats_and_dogs/val/cats/efficientnet_b3_embeddings.npy")
    X_val_dogs = np.load(carpeta + "/dataset/cats_and_dogs/val/dogs/efficientnet_b3_embeddings.npy")

    Xv = np.concatenate((X_val_cats, X_val_dogs), axis=1)

    n_val_cats = X_val_cats.shape[1]
    n_val_dogs = X_val_dogs.shape[1]
    n_val_total = n_val_cats + n_val_dogs

    Yv = np.zeros((2, n_val_total))
    Yv[0, :n_val_cats] = 1
    Yv[1, n_val_cats:] = 1

    return Xt, Yt, Xv, Yv

def pinvEcuacionesNormales(X, Y):
    rango = rango(X)
    print("1")
    n,p = X.shape
    if rango == p and n>p:
        print("a")
        Xt = traspuesta(X)
        L,Lt = cholesky(multiplicar_matrices(Xt,X))
        print("1.1")
        Z = np.zeros((p,n))
        for i in range(n):
            Z[:,i] = sustitucionInferior(L,Xt[:,i])
        print("1.2")
        U = np.zeros((p,n))
        for i in range(n):
            U[:,i] = sustitucionSuperior(Lt,Z[:,i])
        print("1.3")
        W = multiplicar_matrices(Y,U)
        print("1.4")
    elif rango == n:
        if n < p:
            print("b")
            Xt = traspuesta(X)
            print("2")
            L,Lt = cholesky(multiplicar_matrices(X,Xt,))
            print("2.1")
            Z = np.zeros((n,p))
            print(p)
            for i in range(p):
                Z[:,i] = sustitucionInferior(L,X[:,i])
                print(i)
            print("2.2")
            Vt = np.zeros((n,p))
            for i in range(p):
                Vt[:,i] = sustitucionSuperior(Lt,Z[:,i])
            print("2.3")
            V = traspuesta(Vt)
            W = multiplicar_matrices(Y,V)
            print("2.4")
        elif n == p:
            print("c")
            print("3")
            W = multiplicar_matrices(Y,inversa(X))
            print("3.1")
    return W

            
Xt,Yt,Xv,Yv = cargarDataset("/home/Estudiante/Escritorio/LabosALC-main 1/LabosALC-main/template-alumnos") 
#W = pinvEcuacionesNormales(Xt,Yt)

U,S,V = svd_reducida(Xt)

def pinvSVD(U,S,V,Y):
 S_inv= vectorDiagonal(1/S)
 X_pinv= multiplicar_matrices(multiplicar_matrices(traspuesta(V),S_inv),traspuesta(U))
 W= multiplicar_matrices(Y,X_pinv)
 return W

print (pinvSVD(U,S,V,Yt))

#%%
def pinvHouseHolder(Q, R, Y):
    n,p=R.shape
    Qt = traspuesta(Q)
    Vt = np.zeros((p,n))
    print(n)
    for i in range(n):
        Vt[:,i] = sustitucionSuperior(R,Qt)
        print(i)
    W = multiplicar_matrices(Y,traspuesta(Vt))
    #W = multiplicar_matrices(Y,traspuesta(Vt))
    return W

def pinvGramSchmidt(Q, R, Y):
    n,p=R.shape
    Qt = traspuesta(Q)
    Vt = np.zeros((p,n))
    for i in range(n):
        Vt[:,i] = sustitucionSuperior(R,Qt)
    W = multiplicar_matrices(Y,traspuesta(Vt))
    return W

def esPseudoInversa(X, pX, tol=1e-8):
    #Calculo las matrices que voy a necesitar para verifiar de antemano para ahorrar recursos
    XpX = multiplicar_matrices(X,pX)
    pXX = multiplicar_matrices(pX,X)
    
    
    if not matricesiguales(multiplicar_matrices(XpX,X),X,tol):
        return False
    elif not matricesiguales(multiplicar_matrices(pX,XpX),pX,tol):
        return False
    elif not matricesiguales(traspuesta(XpX),XpX,tol):
        return False
    elif not matricesiguales(traspuesta(pXX),pXX):
        return False
    return True
print("empieza")
Q,R = QR_con_HH(traspuesta(Xt))
W2 = pinvHouseHolder(Q,R, Yt)
